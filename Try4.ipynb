{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318e7f02-ac59-4807-a27c-09872ec9e1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'css' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m load_dotenv()\n\u001b[0;32m     69\u001b[0m st\u001b[38;5;241m.\u001b[39mset_page_config(page_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEDUQuery+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m                    page_icon\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:books:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m st\u001b[38;5;241m.\u001b[39mwrite(css, unsafe_allow_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m     74\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mconversation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'css' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from htmlTemplates import css, bot_template, user_template\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    #llm = ChatOpenAI()\n",
    "    llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain\n",
    "\n",
    "\n",
    "def handle_userinput(user_question):\n",
    "    response = st.session_state.conversation({'question': user_question})\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "\n",
    "    for i, message in enumerate(st.session_state.chat_history):\n",
    "        if i % 2 == 0:\n",
    "            st.write(user_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(bot_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "st.set_page_config(page_title=\"EDUQuery+\",\n",
    "                   page_icon=\":books:\")\n",
    "st.write(css, unsafe_allow_html=True)\n",
    "\n",
    "if \"conversation\" not in st.session_state:\n",
    "    st.session_state.conversation = None\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = None\n",
    "\n",
    "st.header(\"Chat with multiple PDFs :books:\")\n",
    "user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "if user_question:\n",
    "    handle_userinput(user_question)\n",
    "\n",
    "with st.sidebar:\n",
    "    st.subheader(\"Your Notes\")\n",
    "    pdf_docs = st.file_uploader(\n",
    "        \"Upload your Notes here and click on 'Process'\", accept_multiple_files=True)\n",
    "    if st.button(\"Process\"):\n",
    "        with st.spinner(\"Processing\"):\n",
    "            # get pdf text\n",
    "            raw_text = get_pdf_text(pdf_docs)\n",
    "\n",
    "            # get the text chunks\n",
    "            text_chunks = get_text_chunks(raw_text)\n",
    "\n",
    "            # create vector store\n",
    "            vectorstore = get_vectorstore(text_chunks)\n",
    "\n",
    "            # create conversation chain\n",
    "            st.session_state.conversation = get_conversation_chain(\n",
    "                vectorstore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4643e8-e274-44fa-a8b1-c1467ca88480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "#from htmlTemplates import css, bot_template, user_template\n",
    "from langchain.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7acecf18-bc51-42af-87bb-7e9afa9a53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d04056b-1691-4659-a325-55b363bb34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5272da66-1283-4d34-a23b-498f8debf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore(text_chunks):\n",
    "    #embeddings = OpenAIEmbeddings()\n",
    "    H\n",
    "    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561c928c-e2ee-4bd1-aba6-6ba5db6f5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI()\n",
    "    # llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5221f9e2-7440-4b4a-9383-5ea8de37d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_userinput(user_question):\n",
    "    response = st.session_state.conversation({'question': user_question})\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "\n",
    "    for i, message in enumerate(st.session_state.chat_history):\n",
    "        if i % 2 == 0:\n",
    "            st.write(user_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(bot_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3a861f-ada9-42a1-a07f-300f59eafae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_dotenv()\n",
    "    st.set_page_config(page_title=\"EDUQuery+\",\n",
    "                       page_icon=\":books:\")\n",
    "    st.write(css, unsafe_allow_html=True)\n",
    "\n",
    "    if \"conversation\" not in st.session_state:\n",
    "        st.session_state.conversation = None\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = None\n",
    "\n",
    "    st.header(\"Chat with multiple PDFs :books:\")\n",
    "    user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "    if user_question:\n",
    "        handle_userinput(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.subheader(\"Your documents\")\n",
    "        pdf_docs = st.file_uploader(\n",
    "            \"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n",
    "        if st.button(\"Process\"):\n",
    "            with st.spinner(\"Processing\"):\n",
    "                # get pdf text\n",
    "                raw_text = get_pdf_text(pdf_docs)\n",
    "\n",
    "                # get the text chunks\n",
    "                text_chunks = get_text_chunks(raw_text)\n",
    "\n",
    "                # create vector store\n",
    "                vectorstore = get_vectorstore(text_chunks)\n",
    "                                # create conversation chain\n",
    "                st.session_state.conversation = get_conversation_chain(\n",
    "                    vectorstore)\n",
    "\n",
    "\n",
    "if __name__ == '_main_':\n",
    "    main()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724d6f8-b9fa-4a4b-a89e-395867e14625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391600e-7335-456c-8a86-a6bec4a07425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
